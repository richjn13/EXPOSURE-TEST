# Project Structure

your_project_name/
├── scrapy.cfg
├── setup.py
├── requirements.txt
├── your_project_name/
│   ├── __init__.py
│   ├── settings.py
│   ├── items.py
│   └── spiders/
│       ├── __init__.py
│       └── flexible_basketball_events_spider.py

# File Contents

## scrapy.cfg
[settings]
default = your_project_name.settings

[deploy]
project = your_project_name

## setup.py
from setuptools import setup, find_packages

setup(
    name='your_project_name',
    version='1.0',
    packages=find_packages(),
    entry_points={'scrapy': ['settings = your_project_name.settings']},
)

## requirements.txt
scrapy==2.5.1
w3lib==1.22.0

## your_project_name/settings.py
BOT_NAME = 'your_project_name'
SPIDER_MODULES = ['your_project_name.spiders']
NEWSPIDER_MODULE = 'your_project_name.spiders'
ROBOTSTXT_OBEY = True

## your_project_name/items.py
import scrapy

class EventItem(scrapy.Item):
    event_name = scrapy.Field()
    event_date = scrapy.Field()
    event_location = scrapy.Field()
    event_url = scrapy.Field()

class TeamItem(scrapy.Item):
    event_name = scrapy.Field()
    team_name = scrapy.Field()
    event_url = scrapy.Field()

## your_project_name/spiders/flexible_basketball_events_spider.py
import scrapy
from scrapy.loader import ItemLoader
from itemloaders.processors import MapCompose
from your_project_name.items import EventItem, TeamItem

class FlexibleBasketballEventsSpider(scrapy.Spider):
    name = 'flexible_basketball_events_spider'
    allowed_domains = ['basketball.exposureevents.com']

    def __init__(self, start_url=None, *args, **kwargs):
        super(FlexibleBasketballEventsSpider, self).__init__(*args, **kwargs)
        if start_url:
            self.start_urls = [start_url]
        else:
            self.start_urls = ['https://basketball.exposureevents.com']

    def parse(self, response):
        event_links = response.css('a[href*="/events/"]::attr(href), a[href*="/tournament/"]::attr(href)').getall()
        
        if event_links:
            for link in event_links:
                yield scrapy.Request(url=response.urljoin(link), callback=self.parse_event)
        else:
            yield from self.parse_event(response)

        next_page = response.css('a.next-page::attr(href), a[href*="page="]::attr(href)').get()
        if next_page:
            yield response.follow(next_page, self.parse)

    def parse_event(self, response):
        event_loader = ItemLoader(item=EventItem(), selector=response)
        event_loader.add_css('event_name', 'h1::text, h2::text', MapCompose(str.strip))
        event_loader.add_css('event_date', 'span.date::text, div.date::text', MapCompose(str.strip))
        event_loader.add_css('event_location', 'span.location::text, div.location::text', MapCompose(str.strip))
        event_loader.add_value('event_url', response.url)
        
        yield event_loader.load_item()

        team_elements = response.css('div.team, li.team, tr.team')
        event_name = response.css('h1::text, h2::text').get()
        
        for team in team_elements:
            team_loader = ItemLoader(item=TeamItem(), selector=team)
            team_loader.add_value('event_name', event_name)
            team_loader.add_css('team_name', '*::text', MapCompose(str.strip))
            team_loader.add_value('event_url', response.url)
            
            yield team_loader.load_item()

        sub_event_links = response.css('a[href*="/events/"], a[href*="/tournament/"]::attr(href)').getall()
        for link in sub_event_links:
            if link != response.url:
                yield scrapy.Request(url=response.urljoin(link), callback=self.parse_event)
